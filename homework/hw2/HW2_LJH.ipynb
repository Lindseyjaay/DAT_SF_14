{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 1: Implement KNN classification, using the sklearn package.\n",
    "\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(3).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93333333333333335"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Question 2: Use the sklearn package to implement cross-validation for your classifier. Use 5 folds for your cross-validation.\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets, feature_selection\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "clf = neighbors.KNeighborsClassifier(11, weights='uniform')\n",
    "clf.fit(iris.data, iris.target)\n",
    "scores = cross_val_score(clf, iris_df.values, iris.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.93333333  1.          1.          0.96666667  1.        ]\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print scores\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 11, 21, 31, 41, 51, 61, 71, 81, 91, 101, 111, 121, 131, 141]\n"
     ]
    }
   ],
   "source": [
    "#Question 3: Use your KNN classifier and cross-validation code from (1) and (2) above to determine the optimal value of K (number of nearest neighbors to consult) for this Iris dataset. Hint: This hyperparameter will be a number between 1 and 150\n",
    "\n",
    "n_neighbors = range(1, 150, 10)\n",
    "print n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.QuadMesh at 0x10e196fd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABA8AAAFwCAYAAADXDFJoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e1ba490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Question 4: Using matplotlib, plot classifier accuracy versus the hyperparameter K for a range of K that you consider interesting. Explain in words what you are seeing.\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(11, weights='uniform')\n",
    "clf.fit(iris.data[:, 2:4], iris.target)\n",
    "\n",
    "\n",
    "h = 0.01\n",
    "\n",
    "# Creating color map\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "# Plotting the decision boundary.\n",
    "x_min, y_min = iris_df.min()[['petal length (cm)', 'petal width (cm)']]\n",
    "x_max, y_max = iris_df.max()[['petal length (cm)', 'petal width (cm)']]\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Putting the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=cmap_light)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Question 5: Now, write your own implementation of cross-validation in Python without using the cross-validation methods from sklearn. Cross validation is a very important concept. Implementing it yourself in Python is the best way to learn and understand it. Compare the results of your cross-validation code with your results using the cross-validation in sklearn.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.data import DataReader\n",
    "import pylab as plt\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "\n",
    "iris_df['Target'] = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame(scale(iris.data), columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_val(folds, degrees, X, y):\n",
    "    n = len(X)\n",
    "    kf = KFold(n, n_folds=folds)\n",
    "    kf_dict = dict([(\"fold_%s\" % i,[]) for i in range(1, folds+1)])\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        print \"Fold: %s\" % fold\n",
    "        X_train, X_test = X.ix[train_index], X.ix[test_index]\n",
    "        y_train, y_test = y.ix[train_index], y.ix[test_index]\n",
    "        # Increase degree of linear regression polynomial order\n",
    "        for d in range(1, degrees+1):\n",
    "            print \"Degree: %s\" % d\n",
    "            # Create the model and fit it\n",
    "            polynomial_features = PolynomialFeatures(\n",
    "                degree=d, include_bias=False\n",
    "            )\n",
    "            linear_regression = LinearRegression()\n",
    "            model = Pipeline([\n",
    "                (\"polynomial_features\", polynomial_features),\n",
    "                (\"linear_regression\", linear_regression)\n",
    "            ])\n",
    "            model.fit(X_train, y_train)\n",
    "            # Calculate the test MSE and append to the\n",
    "            # dictionary of all test curves\n",
    "            y_pred = model.predict(X_test)\n",
    "            test_mse = mean_squared_error(y_test, y_pred)\n",
    "            kf_dict[\"fold_%s\" % fold].append(test_mse)\n",
    "        # Convert these lists into numpy arrays to perform averaging\n",
    "        kf_dict[\"fold_%s\" % fold] = np.array(kf_dict[\"fold_%s\" % fold])\n",
    "    # Create the \"average test MSE\" series by averaging the \n",
    "    # test MSE for each degree of the linear regression model,\n",
    "    # across each of the k folds.\n",
    "    kf_dict[\"avg\"] = np.zeros(degrees)\n",
    "    for i in range(1, folds+1):\n",
    "        kf_dict[\"avg\"] += kf_dict[\"fold_%s\" % i]\n",
    "    kf_dict[\"avg\"] /= float(folds)\n",
    "    return kf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_test_error_curves_vs(sample_dict, random_seeds, degrees):\n",
    "    fig, ax = plt.subplots()\n",
    "    ds = range(1, degrees+1)\n",
    "    for i in range(1, random_seeds+1):\n",
    "        ax.plot(ds, sample_dict[\"seed_%s\" % i], lw=2, label='Test MSE - Sample %s' % i)\n",
    "    ax.plot(ds, sample_dict[\"avg\"], linestyle='--', color=\"black\", lw=3, label='Avg Test MSE')\n",
    "    ax.legend(loc=0)\n",
    "    ax.set_xlabel('Degree of Polynomial Fit')\n",
    "    ax.set_ylabel('Mean Squared Error')\n",
    "    ax.set_ylim([0.0, 4.0])\n",
    "    fig.set_facecolor('white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_test_error_curves_kf(kf_dict, folds, degrees):\n",
    "    fig, ax = plt.subplots()\n",
    "    ds = range(1, degrees+1)\n",
    "    for i in range(1, folds+1):\n",
    "        ax.plot(ds, kf_dict[\"fold_%s\" % i], lw=2, label='Test MSE - Fold %s' % i)\n",
    "    ax.plot(ds, kf_dict[\"avg\"], linestyle='--', color=\"black\", lw=3, label='Avg Test MSE')\n",
    "    ax.legend(loc=0)\n",
    "    ax.set_xlabel('Degree of Polynomial Fit')\n",
    "    ax.set_ylabel('Mean Squared Error')\n",
    "    ax.set_ylim([0.0, 4.0])\n",
    "    fig.set_facecolor('white')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'degrees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a713b06747b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkf_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_fold_cross_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplot_test_error_curves_kf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdegrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'degrees' is not defined"
     ]
    }
   ],
   "source": [
    "    folds = 10\n",
    "    kf_dict = k_fold_cross_val(folds, degrees, X, y)\n",
    "    plot_test_error_curves_kf(kf_dict, folds, degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
